{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel computing with Dask\n",
    "\n",
    "This notebook demonstrates one of Xarray's most powerful features: the ability\n",
    "to wrap [dask arrays](https://docs.dask.org/en/stable/array.html) and allow users to seamlessly execute analysis code in\n",
    "parallel.\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. Xarray DataArrays and Datasets are \"dask collections\" i.e. you can execute\n",
    "   top-level dask functions such as `dask.visualize(xarray_object)`\n",
    "2. Learn that all xarray built-in operations can transparently use dask\n",
    "\n",
    "\n",
    "```{important}\n",
    "Using Dask does not always make your computations run faster!* \n",
    "```\n",
    "\n",
    "Performance will depend on the computational infrastructure you're using (for example, how many CPU cores), how the data you're working with is structured and stored, and the algorithms and code you're running. Be sure to review the [Dask best-practices](https://docs.dask.org/en/stable/best-practices.html) if you're new to Dask!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Dask\n",
    "\n",
    "When we talk about Xarray + Dask, we are *usually* talking about two things:\n",
    "1. `dask.array` as a drop-in replacement for numpy arrays\n",
    "2. A \"scheduler\" that actually runs computations on dask arrays (commonly [distributed](https://docs.dask.org/en/stable/deploying.html))\n",
    "\n",
    "## Introduction to dask.array\n",
    "\n",
    "> Dask Array implements a subset of the NumPy ndarray interface using blocked algorithms, cutting up the large array into many small arrays (*blocks* or *chunks*). This lets us compute on arrays larger than memory using all of our cores. We coordinate these blocked algorithms using Dask graphs.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/dask/dask/main/docs/source/images/dask-array.svg\" style=\"width:35%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.array\n",
    "\n",
    "dasky = dask.array.ones((10, 5), chunks=(2, 2))\n",
    "dasky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why dask.array\n",
    "\n",
    "1. Use parallel resources to speed up computation\n",
    "2. Work with datasets bigger than RAM (\"out-of-core\")\n",
    "    > \"dask lets you scale from memory-sized datasets to disk-sized datasets\"\n",
    "\n",
    "### dask is lazy\n",
    "\n",
    "Operations are not computed until you explicitly request them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dasky.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what did dask do when you called `.mean`? It added that operation to the \"graph\" or a blueprint of operations to execute later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.visualize(dasky.mean(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dasky.mean(axis=-1).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More\n",
    "\n",
    "See the [dask.array tutorial](https://tutorial.dask.org/02_array.html)\n",
    "\n",
    "\n",
    "### Dask + Xarray\n",
    "\n",
    "Remember that Xarray can wrap many different array types. So Xarray can wrap dask arrays too. \n",
    "\n",
    "We use Xarray to enable using our metadata to express our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='readwrite'></a>\n",
    "\n",
    "## Creating dask-backed Xarray objects\n",
    "\n",
    "The `chunks` argument to both `open_dataset` and `open_mfdataset` allow you to\n",
    "read datasets as dask arrays. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# limit the amount of information printed to screen\n",
    "xr.set_options(display_expand_data=False)\n",
    "np.set_printoptions(threshold=10, edgeitems=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\"air_temperature\")\n",
    "ds.air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.tutorial.open_dataset(\n",
    "    \"air_temperature\",\n",
    "    chunks={  # this tells xarray to open the dataset as a dask array\n",
    "        \"lat\": \"auto\",\n",
    "        \"lon\": 25,\n",
    "        \"time\": -1,\n",
    "    },\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The representation (\"repr\" in Python parlance) for the `air` DataArray shows the very nice HTML dask array repr. You can access the underlying chunk sizes using `.chunks`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "All variables in a `Dataset` need _not_ have the same chunk size along\n",
    "common dimensions.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting underlying data\n",
    "\n",
    "There are two ways to pull out the underlying array object in an xarray object.\n",
    "\n",
    "1. `.to_numpy` or `.values` will always return a NumPy array. For dask-backed xarray objects,\n",
    "   this means that compute will always be called\n",
    "2. `.data` will return a Dask array\n",
    "\n",
    "```{tip}\n",
    "Use `to_numpy` or `as_numpy` instead of `.values` so that your code generalizes to other array types (like CuPy arrays, sparse arrays)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.data  # dask array, not numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.air.as_numpy().data  ## numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{admonition} Exercise\n",
    ":class: tip\n",
    "Try calling `ds.air.values` and `ds.air.data`. Do you understand the difference?\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds.air.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='compute'></a>\n",
    "\n",
    "## Lazy computation \n",
    "\n",
    "Xarray seamlessly wraps dask so all computation is deferred until explicitly\n",
    "requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = ds.air.mean(\"time\")\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask actually constructs a graph of the required computation. Here it's pretty simple: The full array is subdivided into 3 arrays. Dask will load each of these subarrays in a separate thread using the default [single-machine scheduling](https://docs.dask.org/en/stable/scheduling.html). You can visualize dask 'task graphs' which represent the requested computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean.data  # dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the graph for the underlying dask array\n",
    "# we ask it to visualize the graph from left to right because it looks nicer\n",
    "dask.visualize(mean.data, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "## Getting concrete values\n",
    "\n",
    "At some point, you will want to actually get concrete values (_usually_ a numpy array) from dask.\n",
    "\n",
    "There are two ways to compute values on dask arrays.\n",
    "\n",
    "1. `.compute()` returns an xarray object *just like a dask array*\n",
    "2. `.load()` replaces the dask array in the xarray object with a numpy array.\n",
    "   This is equivalent to `ds = ds.compute()`\n",
    "   \n",
    "```{tip}\n",
    "There is a third option : \"persisting\". `.persist()` loads the values into distributed RAM. The values are computed but remain distributed across workers. So `ds.air.persist()` still returns a dask array. This is useful if you will be repeatedly using a dataset for computation but it is too large to load into local memory. You will see a persistent task on the dashboard. See the [dask user guide](https://docs.dask.org/en/latest/api.html#dask.persist) for more on persisting\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{admonition} Exercise\n",
    ":class: tip\n",
    "\n",
    "Try running `mean.compute` and then examine `mean` after that. Is it still a dask array?\n",
    "\n",
    ":::{admonition} Solution\n",
    ":class: dropdown\n",
    "\n",
    "Computing returns a numpy array but does not modify in-place. So `mean` still contains a dask array.\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::::{admonition} Exercise\n",
    ":class: tip\n",
    "\n",
    "Now repeat that exercise with `mean.load`.\n",
    "\n",
    ":::{admonition} Solution\n",
    ":class: dropdown\n",
    "\n",
    "`load` modifies an Xarray object in-place so `mean` now contains a numpy array.\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As your data volumes grow and algorithms get more complex it can be hard to print out task graph representations and understand what Dask is doing behind the scenes. Luckily, you can use Dask's 'Distributed' scheduler to get very useful diagnotisic information.\n",
    "\n",
    "First let's set up a `LocalCluster` using [dask.distributed](https://distributed.dask.org/).\n",
    "\n",
    "You can use any kind of Dask cluster. This step is completely independent of\n",
    "xarray. While not strictly necessary, the dashboard provides a nice learning\n",
    "tool.\n",
    "\n",
    "By default, Dask uses the current working directory for writing temporary files.\n",
    "We choose to use a temporary scratch folder `local_directory='/tmp'` in the example below instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "# This piece of code is just for a correct dashboard link mybinder.org or other JupyterHub demos\n",
    "import dask\n",
    "import os\n",
    "\n",
    "# if os.environ.get('JUPYTERHUB_USER'):\n",
    "#    dask.config.set(**{\"distributed.dashboard.link\": \"/user/{JUPYTERHUB_USER}/proxy/{port}/status\"})\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ Click the Dashboard link above. \n",
    "\n",
    "👈 Or click the \"Search\" 🔍 button in the [dask-labextension](https://github.com/dask/dask-labextension) dashboard.\n",
    "\n",
    "```{note}\n",
    "if using the dask-labextension, you should disable the 'Simple' JupyterLab interface (`View -> Simple Interface`), so that you can drag and rearrange whichever dashboards you want. The `Workers` and `Task Stream` are good to make sure the dashboard is working!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dask.array\n",
    "\n",
    "dask.array.ones((1000, 4), chunks=(2, 1)).compute()  # should see activity in dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to our xarray DataSet, in addition to computing the mean, other operations such as indexing will automatically use whichever Dask Cluster we are connected to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.air.isel(lon=1, lat=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and more complicated operations...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean = ds.air.rolling(time=5).mean()  # no activity on dashboard\n",
    "rolling_mean  # contains dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timeseries = rolling_mean.isel(lon=1, lat=20)  # no activity on dashboard\n",
    "timeseries  # contains dask array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed = rolling_mean.compute()  # activity on dashboard\n",
    "computed  # has real numpy values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `mean` still contains a dask array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{tip}\n",
    "While these operations all work, not all of them are necessarily the optimal implementation for parallelism. Usually analysis pipelines need some tinkering and tweaking to get things to work. In particular read the user guidie recommendations for [chunking](https://docs.xarray.dev/en/stable/user-guide/dask.html#chunking-and-performance).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xarray data structures are first-class dask collections.\n",
    "\n",
    "This means you can do things like `dask.compute(xarray_object)`,\n",
    "`dask.visualize(xarray_object)`, `dask.persist(xarray_object)`. This works for\n",
    "both DataArrays and Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "::::{admonition} Exercise\n",
    "Visualize the task graph for a few different computations on `ds.air`!\n",
    "::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell for the exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish up\n",
    "Gracefully shutdown our connection to the Dask cluster. This becomes more important when you are running on large HPC or Cloud servers rather than a laptop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "\n",
    "See the [Xarray user guide on dask](https://docs.xarray.dev/en/stable/user-guide/dask.html). "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
