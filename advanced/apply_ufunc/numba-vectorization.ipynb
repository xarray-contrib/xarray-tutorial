{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fast vectorization with Numba\n",
    "\n",
    "<img src=\"https://numba.pydata.org/_static/numba-blue-horizontal-rgb.svg\" width=\"40%\" align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "tags": []
   },
   "source": [
    "`np.vectorize` is a very convenient function but is unfortunately slow. It is only marginally faster than writing a for loop in Python and looping. \n",
    "\n",
    "A common way to get around this is to write a base interpolation function that can handle nD arrays in a compiled language like C or Fortran and then pass that to `apply_ufunc`.\n",
    "\n",
    "Another option is to use the [numba package](https://numba.pydata.org/) which provides two very convenient decorators to build [numpy universal functions or ufuncs](https://numba.readthedocs.io/en/stable/user/vectorize.html):\n",
    "1. [`vectorize`](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-vectorize-decorator) for functions that act on scalars, and \n",
    "2. [`guvectorize`](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-guvectorize-decorator) for functions that operates on subsets of the array along core-dimensions. Any decorated function gets compiled and will loop over the loop dimensions in parallel when necessary. \n",
    "\n",
    "For `apply_ufunc` the key concept is that we must provide `vectorize=False` (the default) when using Numba vectorized functions. \n",
    "Numba handles the vectorization (or looping) and `apply_ufunc` handles converting Xarray objects to bare arrays and handling metadata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%xmode minimal\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "da = xr.DataArray(\n",
    "    np.arange(12).reshape(3, 4),\n",
    "    dims=(\"x\", \"y\"),\n",
    "    coords={\"x\": [12, 13, 14]},\n",
    "    attrs={\"foo\": \"bar\"},\n",
    ")\n",
    "da"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## `vectorize`\n",
    "\n",
    "Our `squared_error` example from earlier works element-by-element, and is a great example for `vectorize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import vectorize, float64\n",
    "\n",
    "\n",
    "@vectorize([float64(float64, float64)])\n",
    "def squared_error(x, y):\n",
    "    return (x - y) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "See the numba documentation to understand `@vectorize([float64(float64, float64)])`\n",
    "\n",
    "Now use `apply_ufunc` to apply it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr.apply_ufunc(squared_error, da, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## `guvectorize`\n",
    "\n",
    "`guvectorize` is for functions that work on small subsets of the data. Quoting the Numba documentation\n",
    "> While `vectorize()` allows you to write ufuncs that work on one element at a time, the `guvectorize()` decorator takes the concept one step further and allows you to write ufuncs that will work on an arbitrary number of elements of input arrays, and take and return arrays of differing dimensions. The typical example is a running median or a convolution filter.\n",
    "\n",
    "This description should remind you of `apply_ufunc`!\n",
    "\n",
    "We will use the example function `g` from the [numba docs](https://numba.readthedocs.io/en/stable/user/vectorize.html#the-guvectorize-decorator), which adds a scalar `y` to a 1D vector `x`. The `res` argument here will contain the output (this is a Numba detail).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import guvectorize, int64\n",
    "\n",
    "\n",
    "@guvectorize([(int64[:], int64, int64[:])], '(n),()->(n)')\n",
    "def g(x, y, res):\n",
    "    for i in range(x.shape[0]):\n",
    "        res[i] = x[i] + y\n",
    "\n",
    "\n",
    "a = np.arange(5)\n",
    "g(a, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Unlike `squared_error` we cannot pass an Xarray object to `g` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "g(da, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now use `apply_ufunc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xr.apply_ufunc(\n",
    "    g,\n",
    "    da,\n",
    "    1,\n",
    "    input_core_dims=[[\"x\"], []],\n",
    "    output_core_dims=[[\"x\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Notice the following:\n",
    "1. The `guvectorize` decorator includes the concept of \"core dimensions\": `'(n),()->(n)'`. This string means that the `g` takes a 1D vector of size `n`, a scalar, and returns a 1D vector of size `n`. There is one core dimension for the input, and one core dimension for the output. Both core dimensions have the same size.\n",
    "2. That string translates to `input_core_dims=[[\"x\"], []], output_core_dims=[[\"x\"]]` in `apply_ufunc`.\n",
    "3. We don't provide `vectorize=True` to `apply_ufunc` since `numba` will handle the vectorization in compiled code automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## With dask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Use the chunked DataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "da_dask = da.chunk({\"y\": 1})\n",
    "da_dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "::::{admonition} Exercise\n",
    ":class: tip\n",
    "\n",
    "Apply `g` to `da_dask`\n",
    "\n",
    ":::{admonition} Solution\n",
    ":class: dropdown\n",
    "\n",
    "```python\n",
    "xr.apply_ufunc(\n",
    "    g,\n",
    "    da_dask, \n",
    "    1, \n",
    "    input_core_dims=[[\"x\"], []], \n",
    "    output_core_dims=[[\"x\"]],\n",
    "    dask=\"parallelized\",\n",
    ")\n",
    "```\n",
    ":::\n",
    "::::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Next\n",
    "\n",
    "For more, see the numpy.interp end-to-end example in the left sidebar."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
