{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://xarray.pydata.org/en/stable/_static/dataset-diagram-logo.png\" align=\"right\" width=\"30%\">\n",
    "\n",
    "# Grouped Computations with Xarray\n",
    "\n",
    "In this lesson, we discuss how to do scientific computations with defined \"groups\" of data\n",
    "within our xarray objects. Our learning goals are as follows:\n",
    "\n",
    "- Perform \"split / apply / combine\" workflows in Xarray using `groupby`,\n",
    "  including\n",
    "  - reductions within groups\n",
    "  - transformations on groups\n",
    "- Use the `resample`, `rolling` and `coarsen` functions to manipulate data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Dataset\n",
    "\n",
    "First we load a dataset. We will use the\n",
    "[NOAA Extended Reconstructed Sea Surface Temperature (ERSST) v5](https://www.ncdc.noaa.gov/data-access/marineocean-data/extended-reconstructed-sea-surface-temperature-ersst-v5)\n",
    "product, a widely used and trusted gridded compilation of of historical data\n",
    "going back to 1854.\n",
    "\n",
    "Since the data is provided via an\n",
    "[OPeNDAP](https://en.wikipedia.org/wiki/OPeNDAP) server, we can load it directly\n",
    "without downloading anything:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOTE: If hundreds of people connect to this server at once and download the same dataset,\n",
    "###       things might not go so well! Recommended to use the Google Cloud copy instead.\n",
    "\n",
    "# url = \"http://www.esrl.noaa.gov/psd/thredds/dodsC/Datasets/noaa.ersst.v5/sst.mnmean.nc\"\n",
    "# # drop an unnecessary variable which complicates some operations\n",
    "# ds = xr.open_dataset(url, drop_variables=[\"time_bnds\"])\n",
    "# # will take a minute or two to complete\n",
    "# ds = ds.sel(time=slice(\"1960\", \"2018\")).load()\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gcsfs\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(token=\"anon\")\n",
    "ds = xr.open_zarr(\n",
    "    fs.get_mapper(\"gs://pangeo-noaa-ncei/noaa.ersst.v5.zarr\"), consolidated=True\n",
    ").load()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic visualizations of the data, just to make sure it looks\n",
    "reasonable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst[0].plot(vmin=-2, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupby\n",
    "\n",
    "Xarray copies Pandas' very useful groupby functionality, enabling the \"split /\n",
    "apply / combine\" workflow on xarray DataArrays and Datasets.\n",
    "\n",
    "To provide a physically motivated example, let's examine a timeseries of SST at\n",
    "a single point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sst.sel(lon=300, lat=50).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the plot, the timeseries at any one point is totally\n",
    "dominated by the seasonal cycle. We would like to remove this seasonal cycle\n",
    "(called the \"climatology\") in order to better see the long-term variaitions in\n",
    "temperature. We can accomplish this using **groupby**.\n",
    "\n",
    "Before moving forward, w note that xarray correctly parsed the time index,\n",
    "resulting in a Pandas datetime index on the time dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax of Xarray's groupby is almost identical to Pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ds.groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Step\n",
    "\n",
    "The most important argument is `group`: this defines the unique values we will\n",
    "us to \"split\" the data for grouped analysis. We can pass either a DataArray or a\n",
    "name of a variable in the dataset. Lets first use a DataArray. Just like with\n",
    "Pandas, we can use the time index to extract specific components of dates and\n",
    "times. Xarray uses a special syntax for this `.dt`, called the\n",
    "`DatetimeAccessor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.time.dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.time.dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ds.time.dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these arrays in a groupby operation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ds.groupby(ds.time.dt.month)\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray also offers a more concise syntax when the variable you're grouping on is\n",
    "already present in the dataset. This is identical to the previous line:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ds.groupby(\"time.month\")\n",
    "gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data are split, we can manually iterate over the group. The\n",
    "iterator returns the key (group name) and the value (the actual dataset\n",
    "corresponding to that group) for each group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group_name, group_ds in gb:\n",
    "    # stop iterating after the first loop\n",
    "    break\n",
    "print(group_name)\n",
    "group_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply & Combine\n",
    "\n",
    "Now that we have groups defined, it's time to \"apply\" a calculation to the\n",
    "group. Like in Pandas, these calculations can either be:\n",
    "\n",
    "- _aggregation_: reduces the size of the group\n",
    "- _transformation_: preserves the group's full size\n",
    "\n",
    "At then end of the apply step, xarray will automatically combine the aggregated\n",
    "/ transformed groups back into a single object.\n",
    "\n",
    "The most fundamental way to apply is with the `.map` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?gb.map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aggregations\n",
    "\n",
    "`.map` accepts as its argument a function that expects and return xarray\n",
    "objects. We define a custom function. This function takes a single argument--the\n",
    "group dataset--and returns a new dataset to be combined:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_mean(a):\n",
    "    return a.mean(dim=\"time\")\n",
    "\n",
    "\n",
    "gb.map(time_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like Pandas, xarray's groupby object has many built-in aggregation operations\n",
    "(e.g. `mean`, `min`, `max`, `std`, etc):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this does the same thing as the previous cell\n",
    "ds_mm = gb.mean(dim=\"time\")\n",
    "ds_mm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we did what we wanted to do: calculate the climatology at every point in the\n",
    "dataset. Let's look at the data a bit.\n",
    "\n",
    "_Climatlogy at a specific point in the North Atlantic_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mm.sst.sel(lon=300, lat=50).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Zonal Mean Climatolgoy_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_mm.sst.mean(dim=\"lon\").plot.contourf(x=\"month\", levels=12, vmin=-2, vmax=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Difference between January and July Climatology_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_mm.sst.sel(month=1) - ds_mm.sst.sel(month=7)).plot(vmax=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformations\n",
    "\n",
    "Now we want to _remove_ this climatology from the dataset, to examine the\n",
    "residual, called the _anomaly_, which is the interesting part from a climate\n",
    "perspective. Removing the seasonal climatology is a perfect example of a\n",
    "transformation: it operates over a group, but doesn't change the size of the\n",
    "dataset. Here is one way to code it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_time_mean(x):\n",
    "    return x - x.mean(dim=\"time\")\n",
    "\n",
    "\n",
    "ds_anom = ds.groupby(\"time.month\").map(remove_time_mean)\n",
    "ds_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xarray makes these sorts of transformations easy by supporting _groupby\n",
    "arithmetic_. This concept is easiest explained with an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = ds.groupby(\"time.month\")\n",
    "ds_anom = gb - gb.mean(dim=\"time\")\n",
    "ds_anom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can view the climate signal without the overwhelming influence of the\n",
    "seasonal cycle.\n",
    "\n",
    "_Timeseries at a single point in the North Atlantic_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Difference between Jan. 1 2018 and Jan. 1 1960_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ds_anom.sel(time=\"2018-01-01\") - ds_anom.sel(time=\"1960-01-01\")).sst.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouby-Related: Resample, Rolling, Coarsen\n",
    "\n",
    "Resample in xarray is nearly identical to Pandas. It is effectively a group-by\n",
    "operation, and uses the same basic syntax. It can be applied only to time-index\n",
    "dimensions. Here we compute the five-year mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_obj = ds_anom.resample(time=\"5Y\")\n",
    "resample_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom_resample = resample_obj.mean(dim=\"time\")\n",
    "ds_anom_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot()\n",
    "ds_anom_resample.sst.sel(lon=300, lat=50).plot(marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <strong>Note:</strong> <code>resample</code> only works with proper datetime indexes.\n",
    "</div>\n",
    "\n",
    "Rolling is also similar to pandas, but can be applied along any dimension. It\n",
    "works with logical coordinates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom_rolling = ds_anom.rolling(time=12, center=True).mean()\n",
    "ds_anom_rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom.sst.sel(lon=300, lat=50).plot(label=\"monthly anom\")\n",
    "ds_anom_resample.sst.sel(lon=300, lat=50).plot(marker=\"o\", label=\"5 year resample\")\n",
    "ds_anom_rolling.sst.sel(lon=300, lat=50).plot(label=\"12 month rolling mean\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`coarsen` does something similar to `resample`, but without being aware of time.\n",
    "It operates on logical coordinates only but can work on multiple dimensions at a\n",
    "time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom_coarsen_time = ds_anom.coarsen(time=12).mean()\n",
    "\n",
    "ds_anom_rolling.sst.sel(lon=300, lat=50).plot(label=\"12 month rolling mean\")\n",
    "ds_anom_coarsen_time.sst.sel(lon=300, lat=50).plot(marker=\"^\", label=\"12 item coarsen\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# We expect an error here\n",
    "ds_anom_coarsen_space = ds_anom.coarsen(lon=4, lat=4).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom_coarsen_space = ds_anom.isel(lat=slice(0, -1)).coarsen(lon=4, lat=4).mean()\n",
    "ds_anom_coarsen_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_anom_coarsen_space.sst.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Load the following \"basin mask\" dataset, and use it to take a weighted average\n",
    "of SST in each ocean basin. Figure out which ocean basins are the warmest and\n",
    "coldest.\n",
    "\n",
    "**Hint:** you will first need to align this dataset with the SST dataset. Use\n",
    "what you learned in the \"indexing and alignment\" lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin = xr.open_dataset(\n",
    "    \"http://iridl.ldeo.columbia.edu/SOURCES/.NOAA/.NODC/.WOA09/.Masks/.basin/dods\"\n",
    ")\n",
    "basin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
